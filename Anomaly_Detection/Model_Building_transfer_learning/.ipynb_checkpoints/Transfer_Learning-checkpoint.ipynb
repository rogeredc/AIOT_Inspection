{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io,transform\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "#Data Path\n",
    "train_path=\"training_set/\"\n",
    "test_path=\"testing_set/\"\n",
    "\n",
    "#resize\n",
    "w=299\n",
    "h=299\n",
    "c=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pic\n",
    "location_mapping = {'normal':0, 'High':1, 'thick':2, 'fireposition':3,\n",
    "}\n",
    "def read_train_img(path):\n",
    "    cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x) and x.find(\".ipynb_checkpoints\")]\n",
    "    print(cate)\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    classf=[]\n",
    "    for idx,folder in enumerate(cate):\n",
    "        for im in glob.glob(folder+'/*.jpg'):\n",
    "            #print('reading the images:%s'%(im))\n",
    "            fc=folder.split(\"/\", 1)[1]\n",
    "            img=io.imread(im)\n",
    "            img=transform.resize(img,(w,h))\n",
    "            imgs.append(img)\n",
    "            classf= location_mapping[fc]\n",
    "            labels.append(classf)\n",
    "    return np.asarray(imgs,np.float32),np.asarray(labels,np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training_set/fireposition', 'training_set/High', 'training_set/normal', 'training_set/thick']\n"
     ]
    }
   ],
   "source": [
    "X_train_set,Y_train_set=read_train_img(train_path)\n",
    "#資料夾按照類別命名放置圖片樣本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "num_example=X_train_set.shape[0]\n",
    "arr=np.arange(num_example)\n",
    "np.random.shuffle(arr)\n",
    "X_train=X_train_set[arr]\n",
    "Y_train=Y_train_set[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splite the dataset\n",
    "ratio=0.9\n",
    "s=np.int(num_example*ratio)\n",
    "x_train=X_train[:s]\n",
    "y_train=Y_train[:s]\n",
    "x_val=X_train[s:]\n",
    "y_val=Y_train[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot ecodding\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_val = to_categorical(y_val, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "N_CLASSES = 4\n",
    "BATCH_SIZE =5\n",
    "EPOCHS = 300\n",
    "\n",
    "\n",
    "model = InceptionV3(input_shape=(299, 299, 3),weights=None ,classes=N_CLASSES)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "data_generator = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "earlyStop = EarlyStopping(monitor=\"loss\",\n",
    "                          patience=5,\n",
    "                          verbose=1)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(factor=0.3,\n",
    "                             min_lr=1e-12,\n",
    "                             monitor='loss',\n",
    "                             patience=3,\n",
    "                             verbose=1)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'anomaly_detect_model.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)   \n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint('anomaly_detect_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_generator(image_array, label_array, batch_size=32):\n",
    "    while True:\n",
    "        for indexs in range(0, len(image_array), batch_size):\n",
    "            images = image_array[indexs: indexs+batch_size]\n",
    "            labels = label_array[indexs: indexs+batch_size]\n",
    "            yield images, labels\n",
    "cifar_gen = cifar_generator(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(data_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                    steps_per_epoch=len(x_train) / BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[earlyStop, reduceLR])\n",
    "import json\n",
    "hist = model.fit(X_train, y_train, epochs=5, batch_size=batch_size,validation_split=0.1)\n",
    "with open('train_history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(history_dict, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    acc_values = history_dict['acc']\n",
    "    val_acc_values = history_dict['val_acc']\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "    ax1.plot(epochs, loss_values, 'k:', label='training loss')\n",
    "    ax1.plot(epochs, val_loss_values, 'b--', label='validation loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    ax2.plot(epochs, acc_values, 'k:', label='training accuracy')\n",
    "    ax2.plot(epochs, val_acc_values, 'b--', label='validation accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig(\"Training_Report.png\")\n",
    "    \n",
    "plot_loss_acc(history.history, title=\"Training_Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('anomaly_detect_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('anomaly_detect_model.h5')\n",
    "\n",
    "X_test_set,Y_test_set=read_train_img(test_path)\n",
    "y_test = to_categorical(Y_test_set, 4)\n",
    "\n",
    "score = model.evaluate(X_test_set, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "predicted=model.predict(X_test_set)\n",
    "y_pred=[]\n",
    "for i in range(len(predicted)):\n",
    "    a=int(np.argmax(predicted[i], axis=0))\n",
    "    y_pred=np.append(y_pred,a)\n",
    "y_pred=y_pred.astype('int')\n",
    "C=pd.DataFrame(confusion_matrix(Y_test_set, y_pred),\n",
    "               columns=['normal', 'High', 'thick','fireposition'],\n",
    "               index=['normal', 'High', 'thick','fireposition']\n",
    "              )\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def testing_img(path,output_path):\n",
    "    columns=['normal', 'High', 'thick','fireposition']\n",
    "    for idx,im in enumerate(glob.glob(path+'/*.jpg')):\n",
    "            #print('reading the images:%s'%(im))\n",
    "        imgs=[]\n",
    "        img=io.imread(im)\n",
    "        print(im)\n",
    "        img_t=transform.resize(img,(w,h))\n",
    "        imgs.append(img_t)\n",
    "        imgs=np.asarray(imgs,np.float32)\n",
    "        predicted=int(np.argmax(model.predict(imgs)[0], axis=0))\n",
    "        io.imsave(output_path+\"/{}_{}_.jpg\".format(columns[predicted],idx),img)\n",
    "    print(\"Mission Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_img(\"../real_data\",\"../real_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
